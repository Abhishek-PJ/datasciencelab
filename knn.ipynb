import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.neighbors import KNeighborsClassifier
from sklearn.metrics import accuracy_score

# Load the dataset
df = pd.read_csv('breastcancer1.csv')

# Display basic info
display(df.head())
display(df.info())

# Convert 'Diagnosis' column to numeric values (M -> 1, B -> 0)
df['diagnosis'] = df['diagnosis'].map({'M': 1, 'B': 0})

# Select features and target variable
X = df[['texture_mean', 'radius_mean']]
y = df['diagnosis']

# Normalize the features
scaler = StandardScaler()
X_scaled = scaler.fit_transform(X)

# Split the dataset (80% train, 20% test)
X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42)

# Function to train and evaluate KNN for different values of k
def evaluate_knn(k_values):
    accuracies = []
    best_k = 0
    best_accuracy = 0
    best_predictions = None
    
    for k in k_values:
        knn = KNeighborsClassifier(n_neighbors=k)
        knn.fit(X_train, y_train)
        y_pred = knn.predict(X_test)
        accuracy = accuracy_score(y_test, y_pred)
        accuracies.append(accuracy)
        
        print(f'k={k}: Accuracy={accuracy:.4f}')
        
        if accuracy > best_accuracy:
            best_accuracy = accuracy
            best_k = k
            best_predictions = y_pred
    
    # Plot the accuracy vs k values
    plt.plot(k_values, accuracies, marker='o')
    plt.xlabel('Number of Neighbors (k)')
    plt.ylabel('Accuracy')
    plt.title('KNN Performance')
    plt.show()
    
    print(f'Best k: {best_k} with Accuracy: {best_accuracy:.4f}')
    print('\nPredicted vs Actual Values:')
    comparison_df = pd.DataFrame({'Actual': y_test.values, 'Predicted': best_predictions})
    print(comparison_df.head(10))

# Evaluate KNN for k values from 1 to 15
evaluate_knn(range(1, 16))
